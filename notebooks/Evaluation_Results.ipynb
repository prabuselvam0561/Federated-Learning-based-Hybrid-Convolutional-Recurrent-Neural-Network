{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Evaluation Results\n", "\n", "This notebook evaluates the trained model using various metrics."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from evaluation import evaluate_model\n", "import numpy as np\n", "\n", "# Generate synthetic data for demonstration\n", "y_true = np.random.randint(0, 10, 100)\n", "y_pred = np.random.randint(0, 10, 100)\n", "labels = [str(i) for i in range(10)]\n", "\n", "# Evaluate model\n", "results = evaluate_model(y_true, y_pred, labels)\n", "for metric, value in results.items():\n", "    print(f'{metric}: {value}')"]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 4}